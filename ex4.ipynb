{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Excerpts from Exercise 4 from coursera machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import scipy.optimize as op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the data \n",
    "ex4data=loadmat('ex4data1.mat')\n",
    "X=ex4data[\"X\"]\n",
    "y=ex4data[\"y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000 \n",
      "\n",
      "(400,)\n"
     ]
    }
   ],
   "source": [
    "#X holds 5000 images of 400 pixels total (20x20)\n",
    "m=X.shape[0]\n",
    "print(X.shape[0],'\\n')\n",
    "print(X[1,:].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#display one image \n",
    "imgplot = plt.imshow(np.reshape(X[2600,:],(20,20)).T,cmap=plt.get_cmap('Greys'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25, 401) (10, 26)\n"
     ]
    }
   ],
   "source": [
    "#load up the pre-initialized neural network parameters \n",
    "ex4weights=loadmat('ex4weights.mat')\n",
    "Theta1=ex4weights['Theta1']\n",
    "Theta2=ex4weights['Theta2']\n",
    "print(Theta1.shape, Theta2.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "We have a network with input layer of 400, 25 nodes in the hidden layer, and output layer of 10 (for classifying digits 0 to 9).      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer_size  = 400\n",
    "hidden_layer_size = 25\n",
    "num_labels = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first let's set up the results array\n",
    "yk=np.zeros((m,num_labels))\n",
    "\n",
    "for i in range(m):\n",
    "    ind=y[i]\n",
    "    yk[i,ind-1]=1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define an activation function and the gradient\n",
    "def sigmoid(z):\n",
    "    g=1.0/(1.0+np.exp(-z)) \n",
    "    return g\n",
    "\n",
    "def sigmoidGradient(z):\n",
    "    g=sigmoid(z)*(1-sigmoid(z))\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, feed forward to get the cost function (without regularization, which means lambda equals 0) \n",
    "\n",
    "#add bias unit to X and hidden layer and propagate forward \n",
    "a1=np.hstack((np.ones((5000,1)),X)).T\n",
    "z2=Theta1@a1 \n",
    "a2=sigmoid(z2) \n",
    "\n",
    "a2=np.vstack((np.ones((1,5000)),a2))\n",
    "z3=Theta2@a2 \n",
    "hx=sigmoid(z3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost at parameters (loaded from ex4weights): 0.2876291651613189 \n",
      "(this value should be about 0.287629)\n"
     ]
    }
   ],
   "source": [
    "#now compute the cost\n",
    "ksum=np.sum((-yk*np.log(hx.T) - (1-yk)*np.log(1-hx.T)),1); \n",
    "mksum=np.sum(ksum);\n",
    "J=(1/m)*mksum;\n",
    "\n",
    "print(\"Cost at parameters (loaded from ex4weights):\", J, \"\\n\"\n",
    "       \"(this value should be about 0.287629)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost at parameters (loaded from ex4weights): 0.38376985909092365 \n",
      "(this value should be about 0.383770)\n"
     ]
    }
   ],
   "source": [
    "#implement regularization and check the cost again \n",
    "lam=1\n",
    "\n",
    "Theta1sum=np.sum(np.sum((Theta1[:,1:]**2),1))\n",
    "Theta2sum=np.sum(np.sum((Theta2[:,1:]**2),1))\n",
    "J=J+(lam/(2*m))*(Theta1sum+Theta2sum)\n",
    "\n",
    "print(\"Cost at parameters (loaded from ex4weights):\", J, \"\\n\"\n",
    "        \"(this value should be about 0.383770)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#then, implement backpropagation on the neural network we set up earlier \n",
    "# during the feed forward step to compute the gradients for theta 1 and \n",
    "# theta2 \n",
    "\n",
    "# put together the cost and gradient calulation into a function\n",
    "\n",
    "def nnCostFunction(nnparams, X, y, lam):\n",
    "    #re roll the thetas \n",
    "    theta1=nnparams[:hidden_layer_size*(input_layer_size+1)].\\\n",
    "        reshape((hidden_layer_size, (input_layer_size + 1)))\n",
    "    theta2=nnparams[hidden_layer_size*(input_layer_size+1):].\\\n",
    "        reshape((num_labels,(hidden_layer_size+ 1)))\n",
    "    \n",
    "    m = np.shape(X)[0];\n",
    "    J = 0;\n",
    "\n",
    "    #FEED FORWARD \n",
    "    a1=np.hstack((np.ones((5000,1)),X)).T\n",
    "    z2=theta1@a1 \n",
    "    a2=sigmoid(z2) \n",
    "\n",
    "    a2=np.vstack((np.ones((1,5000)),a2))\n",
    "    z3=theta2@a2 \n",
    "    hx=sigmoid(z3)\n",
    "    \n",
    "    #Compute Cost\n",
    "    ksum=np.sum((-yk*np.log(hx.T) - (1-yk)*np.log(1-hx.T)),1); \n",
    "    mksum=np.sum(ksum);\n",
    "    \n",
    "    theta1sum=np.sum(np.sum((theta1[:,1:]**2),1))\n",
    "    theta2sum=np.sum(np.sum((theta2[:,1:]**2),1))\n",
    "    J=J+(lam/(2*m))*(theta1sum+theta2sum)\n",
    "    \n",
    "    return J\n",
    "\n",
    "def nnGrad(nnparams, X, y, lam):\n",
    "    #reroll the thetas \n",
    "    theta1=nnparams[:hidden_layer_size*(input_layer_size+1)].\\\n",
    "        reshape((hidden_layer_size, (input_layer_size + 1)))\n",
    "    theta2=nnparams[hidden_layer_size*(input_layer_size+1):].\\\n",
    "        reshape((num_labels,(hidden_layer_size+1)))\n",
    "  \n",
    "    m = np.shape(X)[0];\n",
    "    theta1_grad = np.zeros(np.shape(theta1));\n",
    "    theta2_grad = np.zeros(np.shape(theta2));\n",
    "\n",
    "    # now implement backpropagation\n",
    "    delta_1=0; \n",
    "    delta_2=0; \n",
    "\n",
    "    for t in range(m): \n",
    "        a1=np.vstack((np.atleast_2d(1),np.atleast_2d(X[t,:]).T))\n",
    "        z2=theta1@a1 \n",
    "        a2=sigmoid(z2) \n",
    "        a2=np.vstack((np.atleast_2d(1),a2))\n",
    "        z3=theta2@a2 \n",
    "        a3=sigmoid(z3)     \n",
    "        d3=a3-np.atleast_2d(yk[t,:]).T; \n",
    "        d2=(theta2[:,1:].T@d3)*sigmoidGradient(z2)\n",
    "        delta_1=delta_1+(d2@a1.T)\n",
    "        delta_2=delta_2+(d3@a2.T)\n",
    "\n",
    "    theta1[:,0]=0; \n",
    "    theta2[:,0]=0; \n",
    "    theta1_grad=(1/m)*delta_1+(lam/m)*theta1; \n",
    "    theta2_grad=(1/m)*delta_2+(lam/m)*theta2; \n",
    "\n",
    "    grad=np.concatenate((theta1_grad.ravel(),theta2_grad.ravel()))\n",
    "    \n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#epsilon_int=0.12; \n",
    "#initial_theta1=np.random.rand(hidden_layer_size,1+input_layer_size) * 2 * epsilon_int - epsilon_int ; \n",
    "#initial_theta2=np.random.rand(num_labels,1+hidden_layer_size) * 2 * epsilon_int - epsilon_int ; \n",
    "#initial_nn_params = np.concatenate((initial_theta1.ravel(), initial_theta2.ravel()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now implement a neural network from start to end \n",
    "# start with the given weights\n",
    "nn_params=np.concatenate((Theta1.ravel(),Theta2.ravel()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train the neural network \n",
    "lam=0\n",
    "thetas=op.minimize(nnCostFunction, nn_params, args=(X,y,lam), \\\n",
    "                   method='CG', jac=nnGrad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     fun: 0.0\n",
       "     jac: array([ 6.18712766e-05,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "        9.66104721e-05, -7.57736846e-04,  7.73329872e-04])\n",
       " message: 'Desired error not necessarily achieved due to precision loss.'\n",
       "    nfev: 113\n",
       "     nit: 0\n",
       "    njev: 101\n",
       "  status: 2\n",
       " success: False\n",
       "       x: array([ 0.00000000e+00, -1.05624163e-08,  2.19414684e-09, ...,\n",
       "       -2.47795788e-01,  1.28009118e+00, -1.32752042e+00])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reroll the result \n",
    "Theta1_opt=thetas.x[:hidden_layer_size*(input_layer_size+1)].\\\n",
    "        reshape((hidden_layer_size, (input_layer_size + 1)))\n",
    "Theta2_opt=thetas.x[hidden_layer_size*(input_layer_size+1):].\\\n",
    "        reshape((num_labels,(hidden_layer_size+ 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now, let's check the prediction\n",
    "a1=np.hstack((np.ones((5000,1)),X)).T\n",
    "z2=Theta1_opt@a1\n",
    "a2=sigmoid(z2) \n",
    "\n",
    "a2=np.vstack((np.ones((1,5000)),a2))\n",
    "z3=Theta2_opt@a2 \n",
    "hx=sigmoid(z3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = [np.argmax(hx[:,i]) for i in range(m)]\n",
    "p = np.add(p,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97.52"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(sum((p==y.ravel()))/5000) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97.52"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#compare to pre loaded Thetas\n",
    "a1=np.hstack((np.ones((5000,1)),X)).T\n",
    "z2=np.dot(Theta1,a1) \n",
    "a2=sigmoid(z2) \n",
    "\n",
    "a2=np.vstack((np.ones((1,5000)),a2))\n",
    "z3=np.dot(Theta2,a2) \n",
    "hx=sigmoid(z3)\n",
    "\n",
    "p = [np.argmax(hx[:,i]) for i in range(m)]\n",
    "p=np.add(p,1)\n",
    "\n",
    "(sum((p==y.ravel()))/5000) * 100"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "In this example I initialized with the pre loaded weights instead of randomly initialized weights due to issues with the optimization algorithm. There is still an issue with the optimization. This was not a successful attempt but perhaps with some more understanding about the vatious optimization algorithms, someone else can figure this out! :) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
